# Overview
___
EDU-AGENT (Educational Development & Understanding - Autonomous Generation Engagement & Navigation Technology) is a comprehensive Agentic AI solution developed through collaboration between the University of Bahrain (UoB) and Amazon Web Services (AWS). The solution transforms traditional academic program management and student recruitment by reducing program analysis and marketing response time from 3 months to 2 weeks.

Powered by Amazon Bedrock and leveraging Foundation Models, EDU-AGENT autonomously: 
- Monitors and analyzes global education trends 
- Benchmarks academic programs against international standards 
- Launches and optimizes targeted recruitment campaigns 
- Provides intelligent guidance to prospective students 
- Generates real-time performance dashboards and narrative reports 

The solution ensures 100% alignment with educational standards while pioneering innovative use of Agentic-AI in education management. Key business outcomes include continuously optimized recruitment strategies, autonomous processing of program benchmarks, increased enrollment rates, and significant reduction in manual monitoring and research efforts.

# Solution Design

*To be appended to README.md*

### **Goal**
> To deliver a production‑like PoC that proves the agentic workflows end‑to‑end
> (trend ingestion → benchmarking → campaign orchestration → student guidance → reporting) 
> with secure, low‑ops, and cost‑conscious AWS services. 
> Designed so each piece can scale to MVP without re‑architecture.

## High Level Design

### Architecture Diagram:
TO BE ADDED - Github friendly format required

### High Level Architecture Breakdown

The goal of this section is to provide a high-level, sectioned overview of the AWS services and components used in implementing the overall EDU-AGENT application architecture. Having read this section, the reader should gain a clear understanding of:

- The **role of each section** from an application perspective
- The **AWS services** used and their **functions** in the overall design
- **Where to start when preparing to code** and how to identify inter-service communications
- The **end-to-end flow** of functionality across key user journeys and use cases

This breakdown is structured to follow the logical order of execution within the system — from data ingestion and processing, through analysis and agentic orchestration, to front-end interaction, campaign automation, and monitoring. Each section includes purpose, architecture flow, deliverables, IAM/security considerations, and measurable success outcomes.

#### 1) Data Ingest & Processing
---

**Services:** 
- AWS EventBridge Scheduler
- AWS Lambda Scripts 
- AWS S3 Bucket(s) 
- AWS Glue ETL/Crawler 
- AWS Glue Data Catalog

**Purpose:** Bring external trend data and platform metrics into the data lake, clean and normalize them for analytics and retrieval.

**How it works (PoC):**
- **EventBridge** runs scheduled rules (e.g., hourly/daily) → invokes **Lambda** scrapers and vendor API pulls.    
- Raw payloads land in the **S3 Raw Data Bucket** using partitioned keys: `source=<vendor>/dt=YYYY-MM-DD/…`
- **Glue Crawler** infers schemas; **Glue ETL** converts JSON→Parquet, deduplicates, enriches before outputting to → **S3 Processed Data Bucket** (curated layer). 
- **Glue Data Catalog** registers tables for Athena/QuickSight and Agent tool access.

**Core deliverables:**
- Implement IaaC design
- Author at least **2 scrapers** (public API + HTML scrape) with retries/backoff.
- Build **1 Glue job** converting to Parquet + adding partitions.
- Create **naming/partitioning standard** and a **data dictionary**.

**Security & IAM:**
- Lambda role: scoped S3 PutObject (raw prefix) + Secrets (API keys). 
- Glue role: read raw, write processed. Deny unencrypted puts.

**PoC success:**
- Data arrives at a set interval into; processed tables queryable in Athena in <5s with sample queries.

#### 2) Data Consolidation & Viewing
---

**Services:** 
- Athena SQL 
- ~~QuickSight Dashboards~~ Replaced with PyChart Library

**Purpose:** Present curated data through analytics dashboards for insight and agent consumption.

**How it works(PoC):**
- Create **Athena views** per domain (trends, benchmarks, engagement). Materialize business logic in SQL.    
- ~~**QuickSight** uses SPICE where needed; dashboards embedded into the portal.~~
- Pychart is used to assemble graphs for display on a sample UI

**Core Deliverables:**
- Implement IaaC design
- 3–5 Athena views + sample queries.    
- 2 Tracking dashboards (Admin KPI + Marketing Campaigns) with RLS placeholder.

**Security:**
- Lake Formation grants per team; QuickSight RLS for department filter (optional in PoC).

**PoC success:**
- Dashboards load in <8s; refresh completes on schedule.

#### 3) Front‑end Website
---
**Services:** 
- Cognito 
- CloudFront + S3 Hosted Static Website 
- API Gateway

**Purpose:** Unified portal for staff and students; enables chat with agent and access to analytics.

**How it works:**
- SPA hosted on **S3+CloudFront**; **Cognito** Hosted UI for sign‑in; **API Gateway HTTP** for REST (embed URL signer, task APIs); **WebSocket** for streaming model responses.

**Core Deliverables:**
- Implement IaaC design
- Build login flow (Cognito Hosted UI) and **role‑based navigation**.    
- Implement **embed signer** endpoint for QuickSight.    
- WebSocket chat page streaming agent responses.

**Security:**
- Cognito groups → JWT scopes → API GW authorizer → IAM policy on Lambdas.

**PoC success:**
- Users can log in, see dashboards, and chat with the agent.

#### 4) Agentic AI Core
---
**Services:** 
- SSM Parameter Store 
- Secrets Manager 
- Step Functions 
- Bedrock Agents & Guardrails 
- DynamoDB

**Purpose:** Orchestrate autonomous tasks (benchmarking, summarization, campaign planning) with controlled prompts and managed state.

**How it works:**
- **SSM Parameter Store** holds prompts/feature flags; **Secrets Manager** holds API tokens.
- **Step Functions** drives flows (e.g., Benchmark_Program, Campaign_Plan_Execute).
- **Bedrock Agents** with Guardrails + tool use (Athena, Kendra, S3 reads) produce analyses.
- **DynamoDB** persists sessions, tool‑state, benchmark results metadata.

**Core Deliverables:**
- Implement IaaC
- 1 Guardrail policy; 1–2 Agent tool integrations (Athena query + Kendra retrieve).
- Build **Benchmark_Program** state machine with error handling + retries.

**Security:**
- Tight IAM for tool use (read‑only Athena workgroup, Kendra query‑only). KMS for DDB/S3/logs.
    
**PoC success:**
- Agent can answer “How does Program X compare globally?” using curated data + KB.
#### 5) Social Media Flow
---]
**Services:**
- SQS Work Queue 
- Lambda Poster (Social Media APIs) 
- Social Media APIs

**Purpose:** Enable human‑in‑the‑loop campaign generation and posting.

**How it works:**
- Agent drafts content → items pushed to **SQS**. Approver action (portal) triggers **Lambda Poster** to call platform APIs using **Secrets Manager** tokens.    
- Metrics pulled back through Ingest pipeline to close the feedback loop.

**Core Deliverables:**
- Implement IaaC
- Create SQS queue + **dead‑letter queue**; implement poster Lambda with simple rate limiting.    
- Add an “Approve & Publish” button in the portal.

**Security:**
- Poster Lambda scoped only to required secrets and queue; audit logs to CloudWatch.
    
**PoC success:**
- A sample campaign post publishes successfully and is traceable end‑to‑end.

#### 6) Internal Knowledge Bases
---
**Services:** 
- Amazon S3 
- (Optional) Amazon Kendra Index

**Purpose:** Provide authoritative answers from university documents, standards, and program specs.

**How it works:**
- Docs uploaded to **S3 Knowledge Base**; **Kendra** data source indexes + syncs; Agent tool queries Kendra with filters.    

**Core Deliverables:**
- Implement IaaC
- Build a minimal Knowledge Base (10–20 docs) + metadata (program, year, department).    
- Wire Kendra Retrieve tool into the agent.

**Security:**
- Knowledge Base bucket policy allows only indexer role to read; agent role query‑only.

**PoC success:**
- Agent cites snippets/links from indexed docs in answers.

#### 7) Monitoring
---
**Services:** 
- Amazon KMS 
- CloudWatch, Alarms & X‑Ray 
- CloudTrail

**Purpose:** Provide operational visibility, security posture tracking, and traceability.

**How it works:**
- **CloudWatch**: JSON logs, metrics, alarms (scraper failure, queue backlog, posting errors). **X‑Ray** traces API → Lambda → Bedrock.    
- **CloudTrail** + **Config** (optional) for API/audit. **KMS CMKs** for S3/DDB/logs.
    
**Core Deliverables:**
- Implement IaaC
- Create 5–7 alarms (Lambda errors, DLQ depth, API 5XX, Athena query failure, Kendra sync failure).
- Build one X‑Ray service map dashboard.

**PoC success:**
- Alarm fires on an induced error; users can trace it in X‑Ray and remediate.

## End‑to‑End Flow (Compact)
---
## Role → Access Cheatsheet (PoC)

- **admins**: all dashboards; invoke agents; approve campaigns.
- **program_admins**: benchmark views; agent Q&A; upload docs to KB (controlled UI).
- **marketing**: campaign dashboard; approve/publish via SQS/Lambda.
- **staff**: trend panels; student chat console.
- **students** (optional PoC): advisor chat + public info only.
---
## What “Done” Looks Like (Demonstrable Outcomes)

1. Dashboard shows last time-periods' trends; a PDF brief can be emailed on demand.
2. Agent answers a benchmark question citing Kendra and querying Athena.
3. Social post created by agent → approved in portal → published via poster Lambda.
4. Alarm triggers on broken scraper; team inspects X‑Ray trace and remediates.
    